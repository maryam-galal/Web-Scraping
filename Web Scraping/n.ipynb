{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# task 1\n",
    "url = \"https://www.baraasallout.com/test.html\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "with open('Extract_Text_Data.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    header = [\"Type\", \"Content\"]\n",
    "    writer.writerow(header)\n",
    "    headings = [h.get_text(strip=True) for h in soup.find_all(['h1', 'h2'])]\n",
    "    paragraphs = [tag.get_text(strip=True) for tag in soup.find_all('p')]\n",
    "    list_items = [tag.get_text(strip=True) for tag in soup.find_all('li')]\n",
    "    for heading in headings:\n",
    "        writer.writerow([\"Heading\", heading])\n",
    "    for paragraph in paragraphs:\n",
    "        writer.writerow([\"Paragraph\", paragraph])\n",
    "    for list_item in list_items:\n",
    "        writer.writerow([\"List Item\", list_item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task 2\n",
    "with open(\"Extract_Table_Data.csv\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    table = soup.find(\"table\")\n",
    "    headers = [h.get_text(strip=True) for h in table.find_all(\"th\")]\n",
    "    writer.writerow(headers) \n",
    "    if table:\n",
    "        rows = table.find_all(\"tr\")\n",
    "        for row in rows[1:]:  # skip the header <th>\n",
    "            cols = row.find_all(\"td\")\n",
    "            writer.writerow([col.text.strip() for col in cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task 3 : extract products info\n",
    "import json\n",
    "product_info = []\n",
    "#<div style=\"display: flex; justify-content: space-around; margin-top: 20px;\">\n",
    "products = soup.select(\"div[style*='display: flex;'] > div\")\n",
    "\n",
    "for c in products:\n",
    "    title = c.find(\"strong\").text.strip() if c.find(\"strong\") else \"\"\n",
    "    price = c.find(\"p\", style=\"color: green;\").text.strip() if c.find(\"p\", style=\"color: green;\") else \"\"\n",
    "    stock = c.find_all(\"p\")[2].text.strip() if len(c.find_all(\"p\")) > 2 else \"\"\n",
    "    button = c.find(\"button\").text.strip() if c.find(\"button\") else \"\"\n",
    "\n",
    "    product_info.append({\n",
    "        \"Book Title\": title,\n",
    "        \"Price\": price,\n",
    "        \"Stock Availability\": stock,\n",
    "        \"Button Text\": button\n",
    "    })\n",
    "\n",
    "with open(\"Product_Information.json\", \"w\", encoding=\"utf-8\") as jsonfile:\n",
    "    json.dump(product_info, jsonfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task 4 : extract form details which user fill in contact us\n",
    "form_details = []\n",
    "form = soup.find(\"form\")\n",
    "if form:\n",
    "    input = form.find_all(\"input\")\n",
    "    for i in input:\n",
    "        field_name = i.get(\"name\", \"\")\n",
    "        input_type = i.get(\"type\", \"\")\n",
    "        default_value = i.get(\"value\", \"\")\n",
    "\n",
    "        form_details.append({\n",
    "            \"Field Name\": field_name,\n",
    "            \"Input Type\": input_type,\n",
    "            \"Default Value\": default_value\n",
    "        })\n",
    "\n",
    "with open(\"Form_Details.json\", \"w\", encoding=\"utf-8\") as jsonfile:\n",
    "    json.dump(form_details, jsonfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task 5 : extract hyperlinks and video link \n",
    "links_and_media = {\n",
    "    \"Hyperlinks\": [],\n",
    "    \"Video Links\": []\n",
    "}\n",
    "# extract hyperlinks <a>\n",
    "for a in soup.find_all(\"a\", href=True):\n",
    "    links_and_media[\"Hyperlinks\"].append(a[\"href\"])\n",
    "# extract video links <iframe>\n",
    "iframe = soup.find(\"iframe\")\n",
    "if iframe and iframe.get(\"src\"):\n",
    "    links_and_media[\"Video Links\"].append(iframe[\"src\"])\n",
    "with open(\"Links_and_Multimedia.json\", \"w\", encoding=\"utf-8\") as jsonfile:\n",
    "    json.dump(links_and_media, jsonfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task 6 : extract featured products info\n",
    "featured_products = []\n",
    "featured_section = soup.find(\"div\", class_=\"products\")\n",
    "if featured_section:\n",
    "    product_cards = featured_section.find_all(\"div\", class_=\"product-card\")\n",
    "    for c in product_cards:\n",
    "        product_id = c.get(\"data-id\", \"\")\n",
    "        name = c.find(\"p\", class_=\"name\").text.strip() if c.find(\"p\", class_=\"name\") else \"\"\n",
    "        price = c.find(\"p\", class_=\"price\", style=\"display: none;\").text.strip() if c.find(\"p\", class_=\"price\", style=\"display: none;\") else \"\"\n",
    "        colors = c.find(\"p\", class_=\"colors\").text.strip() if c.find(\"p\", class_=\"colors\") else \"\"\n",
    "\n",
    "        featured_products.append({\n",
    "            \"id\": product_id,\n",
    "            \"name\": name,\n",
    "            \"price\": price,\n",
    "            \"colors\": colors\n",
    "        })\n",
    "with open(\"Featured_Products.json\", \"w\", encoding=\"utf-8\") as jsonfile:\n",
    "    json.dump(featured_products, jsonfile, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
